# -*- coding: utf-8 -*-
"""Task-1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1OsSB_duITzKhYBKICN2wpRRtidRrUu0u

#**Task 1: Apply Inference on 100 Images**
Our first task is to use any Pre-Trained Object Detection model available online *(In this case we are using Pre-Trained Object Detection model available within PyTorch namely Faster RCNN, Trained on COCO Dataset)* to apply inference on 100 images from the provided COCO Subset dataset. For each image, we have to display the detected objects and their corresponding bounding boxes.
"""

!pip install torch torchvision opencv-python

import torch
import torchvision.transforms as T
from torchvision.models.detection import fasterrcnn_resnet50_fpn
from PIL import Image
import cv2
import numpy as np
from google.colab.patches import cv2_imshow

# Load the pre-trained model
model = fasterrcnn_resnet50_fpn(pretrained=True)
model.eval()

# Define the class names (COCO dataset)
COCO_INSTANCE_CATEGORY_NAMES = [
    '__background__', 'person', 'bicycle', 'car', 'motorcycle', 'airplane',
    'bus', 'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'N/A', 'stop sign',
    'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow',
    'elephant', 'bear', 'zebra', 'giraffe', 'N/A', 'backpack', 'umbrella', 'N/A', 'N/A',
    'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball',
    'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard',
    'tennis racket', 'bottle', 'N/A', 'wine glass', 'cup', 'fork', 'knife', 'spoon',
    'bowl', 'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza',
    'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed', 'N/A', 'dining table', 'N/A',
    'toilet', 'N/A', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone', 'microwave',
    'oven', 'toaster', 'sink', 'refrigerator', 'N/A', 'book', 'clock', 'vase', 'scissors',
    'teddy bear', 'hair drier', 'toothbrush'
]

COCO_INSTANCE_CATEGORY_NAMES[89]

a = [1,
 2,
 3,
 4,
 5,
 6,
 7,
 8,
 9,
 10,
 11,
 13,
 14,
 15,
 16,
 17,
 18,
 19,
 20,
 21,
 22,
 23,
 24,
 25,
 27,
 28,
 31,
 32,
 33,
 34,
 35,
 36,
 37,
 38,
 39,
 40,
 41,
 42,
 43,
 44,
 46,
 47,
 48,
 49,
 50,
 51,
 52,
 53,
 54,
 55,
 56,
 57,
 58,
 59,
 60,
 61,
 62,
 63,
 64,
 65,
 67,
 70,
 72,
 73,
 74,
 75,
 76,
 77,
 78,
 79,
 80,
 81,
 82,
 84,
 85,
 86,
 87,
 88,
 89,
 90]

len(a)

def object_detection_api(img_path, save_path, threshold=0.5, rect_th=3, text_size=1, text_th=3):
    file_name = os.path.basename(img_path)  # Extracts the filename from the img_path
    boxes, pred_cls = get_prediction(img_path, threshold)
    img = cv2.imread(img_path)
    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

    for i, box in enumerate(boxes):
        start_point = (int(box[0][0]), int(box[0][1]))
        end_point = (int(box[1][0]), int(box[1][1]))
        cv2.rectangle(img, start_point, end_point, color=(0, 0, 255), thickness=rect_th)
        cv2.putText(img, pred_cls[i], start_point, cv2.FONT_HERSHEY_SIMPLEX, text_size, (0,255,0), thickness=text_th)

    save_full_path = os.path.join(save_path, file_name)  # Create full save path
    cv2.imwrite(save_full_path, cv2.cvtColor(img, cv2.COLOR_RGB2BGR))  # Save the image
    cv2_imshow(cv2.cvtColor(img, cv2.COLOR_RGB2BGR))  # Display the image

def get_prediction(img_path, threshold):
    img = Image.open(img_path)
    transform = T.Compose([T.ToTensor()])
    img = transform(img)
    pred = model([img])
    # Check if there are any detections
    if len(pred[0]['labels']) > 0:
        # pred_class = [COCO_INSTANCE_CATEGORY_NAMES[i] for i in list(pred[0]['labels'].numpy())]
        pred_class = [COCO_INSTANCE_CATEGORY_NAMES[i] if i < len(COCO_INSTANCE_CATEGORY_NAMES) else 'Unknown' for i in list(pred[0]['labels'].numpy())]
        pred_boxes = [[(i[0], i[1]), (i[2], i[3])] for i in list(pred[0]['boxes'].detach().numpy())]
        pred_score = list(pred[0]['scores'].detach().numpy())

        # Filter out predictions below the threshold
        pred_t = [pred_score.index(x) for x in pred_score if x > threshold][-1]
        pred_boxes = pred_boxes[:pred_t+1]
        pred_class = pred_class[:pred_t+1]

        return pred_boxes, pred_class
    else:
        print("No detections")
        return [], []

import os

def process_folder(input_path, output_path, threshold=0.5, rect_th=3, text_size=1, text_th=3):
    files = [f for f in os.listdir(input_path) if f.endswith(('.png', '.jpg', '.jpeg'))]
    for i, file in enumerate(files, start=1):
        print(f"Processing file {i}/{len(files)}: {file}")
        img_path = os.path.join(input_path, file)
        object_detection_api(img_path, output_path, threshold, rect_th, text_size, text_th)

# Example Use Case
input_path = "/content/drive/MyDrive/MAVISOFT/TASK1_INPUT_DATASET"
output_path = "/content/drive/MyDrive/MAVISOFT/TASK1_OUTPUT_DATASET"
process_folder(input_path, output_path)

"""#**The End**"""